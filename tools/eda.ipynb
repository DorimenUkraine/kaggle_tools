{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e23a3aaee6fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_resampled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mbase_up\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mmodel_RFC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ребалансировка классов для несбалансированных классов (подробнее здесь https://www.kaggle.com/viktorandriichuk/vodafon-acclrtr-3rd-place-adaboost-randomforest/edit)\n",
    "def resample(features, target, repeat_down, repeat_up):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    features_two = features[target == 2]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    target_two = target[target == 2]\n",
    "\n",
    "    features_resampled = pd.concat([features_zeros.sample(n =(int(len(features_zeros)*repeat_down)), \n",
    "                                                            replace=False,random_state=2)] + [features_ones] \n",
    "                                   + [features_two.sample(n =(int(len(features_two)*repeat_up)), \n",
    "                                                            replace=True,random_state=2)])\n",
    "    \n",
    "    target_resampled = pd.concat([target_zeros.sample(n =(int(len(target_zeros)*repeat_down)),\n",
    "                                                        replace=False)] + [target_ones] \n",
    "                                 + [target_two.sample(n =(int(len(target_two)*repeat_up)), \n",
    "                                                            replace=True)])\n",
    "    features_resampled, target_resampled = shuffle(features_resampled, target_resampled, random_state=12345)\n",
    "    features_resampled.reset_index(drop = True, inplace = True)\n",
    "    target_resampled.reset_index(drop = True, inplace = True)\n",
    "    return features_resampled, target_resampled\n",
    "\n",
    "base_up = pd.DataFrame()\n",
    "\n",
    "model_RFC = RandomForestClassifier(n_estimators = 50, random_state = 2)\n",
    "\n",
    "for i in np.arange(0.37, 0.46, 0.02):\n",
    "    for j in np.arange(2.2, 2.5, 0.05):\n",
    "        features_resampled, target_resampled = resample(features_train_big, target_train_big, i , j)\n",
    "        model_RFC.fit(features_resampled, target_resampled)\n",
    "        base_up.loc[str(round(i,2)) + \" \" +str(round(j,2)) ,'Precision'] = precision_score(target_valid, model_RFC.predict(features_valid), average='macro')\n",
    "        base_up.loc[str(round(i,2)) + \" \" +str(round(j,2)) ,'Recall'] = recall_score(target_valid, model_RFC.predict(features_valid), average='macro')\n",
    "        base_up.loc[str(round(i,2)) + \" \" +str(round(j,2)),'F1'] = f1_score(target_valid, model_RFC.predict(features_valid), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Функция print_basic_info, для вывода информации о массиве, и его переменных.**\n",
    "\n",
    "#* base - название базы данных\n",
    "#* info - 1: вывод информации о массиве, другое: не вывод\n",
    "#* describe - 1: вывод описания переменных массива, другое: не вывод        \n",
    "#* duplicat - 1: вывод количества полных дублей\n",
    "#* head - n: вывод примера базы (вывод n - строк), n < 1: не вывод\n",
    "\n",
    "def print_basic_info(base, info, describe, duplicat, head):\n",
    "    if info == 1:\n",
    "        print(base.info())  \n",
    "    if head >= 1:\n",
    "        display(base.head(head))\n",
    "    if describe == 1:\n",
    "        for i in base.columns:\n",
    "            print(base[i].describe())\n",
    "    if duplicat == 1:\n",
    "        print(base[base.duplicated() == True][base.columns[0]].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Функция ft_namecount__, для вывода названия переменной, частотной нормированной таблицы и описания переменной.\n",
    "\n",
    "#5 входных параметров:\n",
    "\n",
    "#* *base* - название базы данных\n",
    "#* *name* - название переменной в базе\n",
    "#* *table* - 1: вывод частотной нормированной таблицы, 0: не вывод\n",
    "#* *sort* - 1: сортировка таблицы по лейблам переменной, 0: не сортировка\n",
    "#* *describe* - 1: вывод описания переменной, 0: не вывод\n",
    "#* *hist* - 1: вывод описания переменной, 0: не вывод\n",
    "#* *bins* -  кол-во столцов для hist, по-умолчанию auto\n",
    "\n",
    "def ft_name_count (base, name , table, sort, describe, hist, bins='auto'):\n",
    "    if table != 0:\n",
    "        s = (base[name].value_counts(normalize=True))\n",
    "        if sort != 0:\n",
    "            s.sort_index(inplace=True)\n",
    "        print(s)\n",
    "    if describe != 0:\n",
    "        print(base[name].describe())\n",
    "    \n",
    "    if hist != 0:\n",
    "        base[name].hist(bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Беглый анализ колонки и удаление, если много пропусков\n",
    "col_for_drop = []\n",
    "\n",
    "def col_info_train(col):\n",
    "\n",
    "    if col.isnull().sum() > 0:\n",
    "        percent_isnull = (col.isnull().sum() / len(col)) * 100\n",
    "        print(col.name)\n",
    "        print('Количество пропусков: {}'.format(col.isnull().sum()))\n",
    "        print('% пропусков: {}'.format(percent_isnull))\n",
    "        print('---')       \n",
    "        \n",
    "    \n",
    "        # Удалю признак, в котором есть пропусков больше 10%\n",
    "        if percent_isnull > 10:\n",
    "            col_for_drop.append(col.name)\n",
    "            train.drop([col.name], axis='columns', inplace=True)\n",
    "        \n",
    "\n",
    "for col in train:\n",
    "    col_info_train(train[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр гистограммы для признака\n",
    "def feature_hist(data, col):\n",
    "    sns.countplot(data[ col])\n",
    "    plt.title('Histogram for default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Беглый просмотр данных в признаке\n",
    "def col_info(data, col, bins):\n",
    "    percent_isnull = (data[col].isnull().sum()) / len(data[col]) * 100\n",
    "    print('Название колонки: {}'.format(data[col].name))\n",
    "    print('Количество пропусков: {}'.format(data[col].isnull().sum()))\n",
    "    print('% пропусков: {}'.format(round(percent_isnull, 2)))\n",
    "    print('{},'.format(data[col].describe()))\n",
    "    print('Распределение:\\n{},'.format(data[col].value_counts()))\n",
    "    data[col].hist(bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация признаков и пропусков\n",
    "def viz_na(data):\n",
    "    \"\"\"NA visualisation\"\"\"\n",
    "    global cols\n",
    "    cols = data.columns # запишем названия строки сделаем переменную глобальной\n",
    "    # определяем цвета \n",
    "    # желтый - пропущенные данные, синий - не пропущенные\n",
    "    colours = ['#000099', '#ffff00'] \n",
    "    sns.heatmap(data[cols].isnull(), cmap=sns.color_palette(colours))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "viz_na(train)\n",
    "viz_na(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика пропусков \n",
    "def stat_na_per_percent(data):\n",
    "    print(f'{data.shape}')\n",
    "    for col in data.columns:\n",
    "        pct_missing = np.mean(data[col].isnull())\n",
    "        if pct_missing > 0: # выведем только те, где больше 0\n",
    "            print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "    print(\"END\", end = '\\n\\n')\n",
    "    \n",
    "stat_na_per_percent(train)\n",
    "stat_na_per_percent(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропущенные данные и выбросы\n",
    "\n",
    "# В добавок к некорректному определению типов данных, другая частая проблема — это пропуски в данных.\n",
    "# У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью.\n",
    "\n",
    "# Для начала попробуем оценить масштаб проблемы\n",
    "\n",
    "# Функция считает ошибочные данные в колонке\n",
    "def missing_values_table(df):\n",
    "        # Всего ошибочных данных (это я уже сделал выше, но выведу их и здесь для наглядности)\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Процент ошибочных данных\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Тип данных каждой колонки\n",
    "        sm_cols = [c for c in sm.columns]\n",
    "\n",
    "        cat_dtypes_dict = {}\n",
    "\n",
    "        for ct in sm_cols:\n",
    "            cat_dtypes_dict.update({sm[ct].name: sm[ct].dtype})\n",
    "\n",
    "        cat_dtypes = pd.Series(cat_dtypes_dict) \n",
    "      \n",
    "        # Сделаем датафрейм с результатами\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent, cat_dtypes], axis=1)\n",
    "        \n",
    "        # Переназовем колонки\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values', 2 : 'Types'})\n",
    "        \n",
    "#         # Отсортируем данные и исключим колонки, в которых нет пропусков\n",
    "#         mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "#             mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "#         '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "        # Отсортируем данные с учетом колонок, в которых нет пропусков\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Выведем итоговую информацию\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Вернем датафрейм с информацией об ошибочных данных\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values_table(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим числовые и категориальные признаки в отдельные листы:\n",
    "\n",
    "categorical_columns = [c for c in sm.columns if sm[c].dtype.name == 'object']\n",
    "numerical_columns   = [c for c in sm.columns if sm[c].dtype.name != 'object']\n",
    "print('Категориальные признаки:', categorical_columns)\n",
    "print('Числовые признаки:', numerical_columns)\n",
    "                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
